---
title: "Prediction Modeling for Heart Disease"
author: "Gemini"
date: "2025-07-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This script builds and evaluates several machine learning models to predict the presence of heart disease. We will compare the performance of unpenalized logistic regression, elastic net regression, and LightGBM. The primary evaluation metric will be the Area Under the Receiver Operating Characteristic Curve (AUROC).

## 1. Load Data and Libraries

First, we load the necessary libraries and the processed heart disease dataset.

```{r load-data}
# Install packages if necessary
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, caret, glmnet, lightgbm, pROC)

# Load the processed data
heart_data <- read_csv("../data/heart_data.csv")

# Display the first few rows of the data
head(heart_data)
```

## 2. Data Splitting

We split the data into training and testing sets to evaluate model performance. We will use an 80/20 split.

```{r split-data}
set.seed(123) # for reproducibility
train_index <- createDataPartition(heart_data$any_heart_disease, p = 0.8, list = FALSE)
train_data <- heart_data[train_index, ]
test_data <- heart_data[-train_index, ]
```

## 3. Model Training and Tuning

### 3.1. Unpenalized Logistic Regression

We start with a standard logistic regression model.

```{r logistic-regression}
# Train the model
log_model <- glm(any_heart_disease ~ ., data = train_data, family = "binomial")

# Make predictions on the test set
log_pred <- predict(log_model, newdata = test_data, type = "response")

# Calculate AUROC
log_roc <- roc(test_data$any_heart_disease, log_pred)
log_auroc <- auc(log_roc)
print(paste("Logistic Regression AUROC:", log_auroc))
```

### 3.2. Elastic Net (glmnet)

Next, we train an elastic net model, which combines L1 and L2 regularization. We will use cross-validation to tune the `alpha` and `lambda` hyperparameters.

```{r elastic-net}
# Prepare the data for glmnet
x_train <- model.matrix(any_heart_disease ~ ., data = train_data)[, -1]
y_train <- train_data$any_heart_disease
x_test <- model.matrix(any_heart_disease ~ ., data = test_data)[, -1]
y_test <- test_data$any_heart_disease

# Get column names from training data
train_cols <- colnames(x_train)

# Get column names from test data
test_cols <- colnames(x_test)

# Find missing columns
missing_cols <- setdiff(train_cols, test_cols)

# Add missing columns to x_test and fill with 0
if (length(missing_cols) > 0) {
  for (col in missing_cols) {
    # Create a new column with the missing name and fill with 0
    x_test <- cbind(x_test, 0)
    colnames(x_test)[ncol(x_test)] <- col
  }
}

# Ensure the column order is the same
x_test <- x_test[, train_cols]

# Set up cross-validation
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)

# Tune the model
set.seed(123)
enet_model <- train(
  x = x_train,
  y = factor(y_train, labels = c("No", "Yes")),
  method = "glmnet",
  trControl = train_control,
  metric = "ROC",
  tuneLength = 10
)

# Make predictions
enet_pred <- predict(enet_model, newdata = x_test, type = "prob")[, "Yes"]

# Calculate AUROC
enet_roc <- roc(y_test, enet_pred)
enet_auroc <- auc(enet_roc)
print(paste("Elastic Net AUROC:", enet_auroc))
```

### 3.3. LightGBM

Finally, we train a LightGBM model, a gradient boosting framework. We will tune its hyperparameters using cross-validation.

```{r lightgbm}
# Prepare the data for LightGBM
lgb_train <- lgb.Dataset(data = x_train, label = y_train)

# Set up hyperparameter tuning grid
tune_grid <- expand.grid(
  nrounds = c(100, 200),
  max_depth = c(3, 6, 9),
  eta = c(0.01, 0.1),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

# Tune the model
set.seed(123)
lgbm_model <- train(
  x = x_train,
  y = factor(y_train, labels = c("No", "Yes")),
  method = "xgbTree",
  trControl = train_control,
  metric = "ROC",
  tuneGrid = tune_grid,
  verbose = 0
)


# Make predictions
lgbm_pred <- predict(lgbm_model, newdata = x_test, type = "prob")[, "Yes"]

# Calculate AUROC
lgbm_roc <- roc(y_test, lgbm_pred)
lgbm_auroc <- auc(lgbm_roc)
print(paste("LightGBM AUROC:", lgbm_auroc))
```

## 4. Model Comparison

Now we compare the AUROC scores of the three models.

```{r model-comparison}
# Create a data frame with the results
results <- data.frame(
  Model = c("Logistic Regression", "Elastic Net", "LightGBM"),
  AUROC = c(log_auroc, enet_auroc, lgbm_auroc)
)

# Print the results
print(results)

# Plot the ROC curves
plot(log_roc, col = "blue", main = "ROC Curve Comparison")
plot(enet_roc, col = "red", add = TRUE)
plot(lgbm_roc, col = "green", add = TRUE)
legend("bottomright", legend = c("Logistic Regression", "Elastic Net", "LightGBM"), col = c("blue", "red", "green"), lty = 1)
```